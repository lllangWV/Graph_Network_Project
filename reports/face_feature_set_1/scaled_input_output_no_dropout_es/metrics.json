{
    "train_mse": [
        0.016380468620891746,
        0.009362223082028005,
        0.008665242612738112,
        0.007932784209904844,
        0.007221997433501586,
        0.006375723588972002,
        0.005549766201287614,
        0.004892589116615547,
        0.004434915180776286,
        0.004205691428092423,
        0.004136981095079136,
        0.004457065476009424,
        0.004568006263288285,
        0.004563076732952574,
        0.004379840379075724,
        0.004130454370244885,
        0.003837449147974677,
        0.003548096815386782,
        0.003253918011060436,
        0.0029673486143227752,
        0.002696495204096369,
        0.0024496895865652886,
        0.0022584813971622975,
        0.0020878182034803684,
        0.0019493898209871038,
        0.001793760052624208,
        0.0016876640959689762,
        0.0015900523901130862,
        0.001504685652977899,
        0.0014599770758307856,
        0.0014118838836365598,
        0.0013515808701011537,
        0.001297404915165336,
        0.0012695788993113699,
        0.001237546747114618,
        0.0011149056094580416,
        0.0010556585978599665,
        0.0010641745993174967,
        0.0009833338494006207,
        0.0009749992771980638,
        0.0009645731946979388,
        0.000959481098067668,
        0.000960615917914319,
        0.0009878716543207527,
        0.0010262276146958099,
        0.0010474728475092134
    ],
    "test_mse": [
        129.14902430637315,
        62.728297704927336,
        34.768150397322394,
        23.77018081600016,
        17.948955935531888,
        14.186842630532654,
        11.890510446645997,
        9.78491626883095,
        7.9556319672953,
        6.6275482394478535,
        5.618822581473399,
        4.691812776119067,
        3.905650749887255,
        3.2388676982373,
        2.6370841176672415,
        2.214671173683283,
        1.9487190588631413,
        1.6866486526348374,
        1.3004584227773277,
        1.1996213766661556,
        1.079089842736721,
        0.9366913764652881,
        0.6834661741317674,
        0.5719890330537137,
        0.5707630038854073,
        0.5579759139694612,
        0.5729139790584502,
        0.5715122345877304,
        0.6042305732421069,
        0.6073833501432091,
        0.6472595422105356,
        0.6629785180345855,
        0.6849170655266128,
        0.6890363234349273,
        0.680619981224564,
        0.6583349850367416,
        0.6617825698446144,
        0.6726295201277191,
        0.6897120178909972,
        0.7000676018386994,
        0.6850165959466804,
        0.6902267133703969,
        0.705111654869556,
        0.6923857464306903,
        0.6944562876279551,
        0.7147708015982062
    ],
    "train_mape": [
        7.012430267905658e-05,
        5.374729467385304e-05,
        4.496040769513095e-05,
        4.206523383975569e-05,
        3.900906545819804e-05,
        3.514698744606543e-05,
        3.1305512597845835e-05,
        2.867813076214528e-05,
        2.7610837515207646e-05,
        2.7257230905223825e-05,
        2.7523853473114465e-05,
        2.8513105474584504e-05,
        2.8894278902818925e-05,
        2.894392976876946e-05,
        2.791471825221251e-05,
        2.6736381668918122e-05,
        2.508933833971122e-05,
        2.37762198700214e-05,
        2.2360521183746686e-05,
        2.0088394795142553e-05,
        1.7667650999260106e-05,
        1.6171757142693673e-05,
        1.5573688035060937e-05,
        1.5427673677015817e-05,
        1.534014312161136e-05,
        1.5060125664138868e-05,
        1.5428398434733562e-05,
        1.5716826979482086e-05,
        1.6010179769421663e-05,
        1.6251016076229954e-05,
        1.642965530997215e-05,
        1.673645493016941e-05,
        1.6837360021720164e-05,
        1.6406665550561916e-05,
        1.56258966344697e-05,
        1.579195808075308e-05,
        1.6440814437029307e-05,
        1.695219890799851e-05,
        1.7535775602340322e-05,
        1.8034210496392164e-05,
        1.8736725216449242e-05,
        1.9065273471486424e-05,
        1.9521417422999162e-05,
        2.0144779048940425e-05,
        2.0543972381477502e-05,
        2.092811344661214e-05
    ],
    "test_mape": [
        1.0134811184623025,
        0.7087606374790828,
        0.52744317880239,
        0.4317028664729812,
        0.37223464502445,
        0.329703209540722,
        0.30091392333534633,
        0.2721205566247756,
        0.24453783022578468,
        0.22248542048460382,
        0.2053151477911425,
        0.18818285694578663,
        0.17334857944462617,
        0.159190024767833,
        0.14384862164628098,
        0.13102166646752844,
        0.12237645194611767,
        0.11303565471263771,
        0.0974185192237862,
        0.09244686174629764,
        0.08539382032838395,
        0.07663999784695492,
        0.05826388248401186,
        0.04615437818574719,
        0.042421334158544516,
        0.03751445616150952,
        0.034369090307419276,
        0.029360708177343688,
        0.029884334436660123,
        0.02534518101972274,
        0.03023327079559253,
        0.028948002262040973,
        0.030758512375706978,
        0.02878471207804978,
        0.027496070220050486,
        0.023676951733333142,
        0.021275446030565283,
        0.022552715995433657,
        0.02601842249912972,
        0.028282448765821755,
        0.022952805839436638,
        0.02587415493855422,
        0.028854320058599114,
        0.023067509818991475,
        0.022012230326336892,
        0.024424805538728833
    ],
    "trainable_params": 3880,
    "model": "PolyhedronResidualModel(\n  (relu): ReLU()\n  (cg_conv_layers): Sequential(\n    (0): CGConv(9, dim=15)\n    (1): CGConv(9, dim=15)\n    (2): CGConv(9, dim=15)\n    (3): CGConv(9, dim=15)\n  )\n  (mlp_1): MLP(\n    (layers): ModuleList(\n      (0): Linear(in_features=9, out_features=36, bias=True)\n      (1): ReLU()\n    )\n    (proj): Linear(in_features=36, out_features=9, bias=True)\n  )\n  (mlp_2): MLP(\n    (layers): ModuleList(\n      (0): Linear(in_features=9, out_features=36, bias=True)\n      (1): ReLU()\n    )\n    (proj): Linear(in_features=36, out_features=9, bias=True)\n  )\n  (out_layer): Linear(in_features=9, out_features=1, bias=True)\n  (ln1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n  (ln2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n)"
}